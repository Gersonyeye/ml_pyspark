{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c7dba55",
   "metadata": {},
   "source": [
    "# Modelos de Clasificación de PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b0dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Forzar a Spark a usar el Python de tu venv\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59fdf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Models') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99681c0",
   "metadata": {},
   "source": [
    "### Regresión logística binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79871a74",
   "metadata": {},
   "source": [
    "La regresión logística es un método popular para predecir una respuesta categórica. Es un caso especial de modelos lineales generalizados que predice la probabilidad de los resultados. \n",
    "\n",
    "En spark.ml la regresión logística se puede utilizar para predecir un **resultado binario** mediante el uso de la regresión logística binomial, o se puede utilizar para predecir un **resultado multiclase** mediante el uso de la regresión logística multinomial. \n",
    "\n",
    "Use el parámetro **family** para seleccionar entre estos dos algoritmos, o déjelo sin configurar y Spark deducirá la variante correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c39151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (692,[272,300,323,350,351,378,379,405,406,407,428,433,434,435,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.52068987138421e-05,-8.115773146847101e-05,3.814692771846369e-05,0.0003776490540424337,0.00034051483661944103,0.0005514455157343105,0.0004085386116096913,0.000419746733274946,0.0008119171358670028,0.0005027708372668751,-2.3929260406601844e-05,0.000574504802090229,0.0009037546426803721,7.818229700244018e-05,-2.1787551952912764e-05,-3.4021658217896256e-05,0.0004966517360637634,0.0008190557828370367,-8.017982139522704e-05,-2.7431694037836214e-05,0.0004810832226238988,0.00048408017626778765,-8.926472920011488e-06,-0.00034148812330427335,-8.950592574121486e-05,0.00048645469116892167,-8.478698005186209e-05,-0.0004234783215831763,-7.29653577763134e-05])\n",
      "Intercept: -0.5991460286401435\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, \n",
    "                        regParam=0.3, \n",
    "                        elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, \n",
    "                         elasticNetParam=0.8, \n",
    "                         family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Predict with the test dataset\n",
    "predictions = mlrModel.transform(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e77ebe",
   "metadata": {},
   "source": [
    "### Árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27353e43",
   "metadata": {},
   "source": [
    "Los árboles de decisión para la clasificación son uno de los algoritmos de aprendizaje automático más antiguos y sencillos. Son populares debido a su **fácil interpretación visual**. Sin embargo, en la práctica, tienden a **sobreajustar** los datos de entrenamiento, lo que conduce a un rendimiento deficiente al intentar hacer predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d353b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|(692,[123,124,125...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[127,128,129...|\n",
      "|       1.0|         1.0|(692,[127,128,129...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.047619 \n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_24c33605fdbe, depth=1, numNodes=3, numClasses=2, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", \n",
    "                            featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d05996",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abf235",
   "metadata": {},
   "source": [
    "Estos combinan muchos (cientos o miles) de árboles de decisión, donde tomamos muestras aleatorias de nuestras observaciones y predictores para formar nuevos árboles.\n",
    "Los random forest **reducen en gran medida la posibilidad de sobreajuste** (es decir, reduce la varianza) promediando varios árboles; esto a veces se denomina sabiduría de las multitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e358a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(692,[123,124,125...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "|           0.0|  0.0|(692,[126,127,128...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_724bccf4ffbd, numTrees=10, numClasses=2, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", \n",
    "                            featuresCol=\"indexedFeatures\", \n",
    "                            numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a6fd9",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5deefd0",
   "metadata": {},
   "source": [
    "Gradient Boosting es una mejora en Random Forest. Ahora, en lugar de simplemente ajustar árboles agregados con bootstrap, tenemos en cuenta el **rendimiento de los árboles intermedios**. \n",
    "\n",
    "Usando estos árboles intermedios, ajustamos nuestros pesos de árboles futuros.\n",
    "Se cogen los residuos donde fallaban los modelos y ajustan el próximo árbol a estos residuos y así sucesivamente para ir mejorando donde se obtenian malos resultados. \n",
    "\n",
    "\"Gradient Boosting hereda todas las buenas características de los árboles (selección de variables, datos faltantes, predictores mixtos) y mejora las características débiles, como el rendimiento de la predicción\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58cda62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|(692,[95,96,97,12...|\n",
      "|       1.0|         1.0|(692,[98,99,100,1...|\n",
      "|       1.0|         1.0|(692,[100,101,102...|\n",
      "|       1.0|         1.0|(692,[121,122,123...|\n",
      "|       1.0|         1.0|(692,[123,124,125...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.0322581\n",
      "GBTClassificationModel: uid = GBTClassifier_9ab59c416fa8, numTrees=10, numClasses=2, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a32b8",
   "metadata": {},
   "source": [
    "### Clasificador de perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e442178",
   "metadata": {},
   "source": [
    "El clasificador de perceptrones multicapa (MLPC) es un clasificador basado en la **red neuronal artificial feedforward** . MLPC consta de múltiples capas de nodos. Cada capa está completamente conectada a la siguiente capa de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4445eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [4, 5, 4, 3]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "result = model.transform(test)\n",
    "\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f6b3e",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50162a44",
   "metadata": {},
   "source": [
    "Construye un **hiperplano o un conjunto de hiperplanos** en un espacio de dimensión alta o infinita, que se puede utilizar para clasificación, regresión u otras tareas. Intuitivamente, se logra una buena separación por el hiperplano que tiene la mayor distancia a los puntos de datos de entrenamiento más cercanos de cualquier clase (el llamado margen funcional), ya que en general, cuanto mayor es el margen, menor es el error de generalización del clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c1b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00015154081891400172,-3.4357432628275696e-05,6.8868723771654e-05,0.0005825396368790324,0.0002658667437974877,-5.4448990232205866e-06,-0.000410876298911309,-0.00023771334401618933,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0015051243197375345,0.0005056741785679464,0.0007739871946118443,-7.439317729362511e-05,2.2395429551533054e-07,2.1502767568913162e-05,4.000155795906807e-05,2.841045988826015e-05,1.2172703998609027e-05,-1.4702408529921009e-05,-4.00596456869388e-05,3.0693747761902103e-06,0.00015395475863074347,0.00015205858963404883,-0.00021785419667457335,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0015601898436303722,0.0005308529758410391,0.00043970093082435635,0.00017801052523689232,1.043216856553289e-06,-4.5215767842958954e-05,-5.3647355919213394e-06,-5.082816080173388e-05,-8.719944876885247e-05,-0.00010329102584755742,-5.720372189549548e-05,-1.528195691009415e-05,-7.516369861689159e-06,5.902800318287996e-06,6.192129140070359e-06,-2.9020218182793853e-05,-0.0001780956677466199,-9.983865716687172e-05,-0.0006061632756560069,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0007310603838725167,0.0003393134198685142,0.0,0.0,4.7022680265078297e-07,-3.0241317159223483e-05,-7.103481041680342e-05,-6.108515880287018e-05,-3.889276771633549e-05,-8.65269800463204e-06,-2.834194124489035e-05,-2.046641541101444e-05,-3.6745739150178985e-05,-4.947197882344778e-06,-3.218855441846359e-05,-2.8248522773451987e-05,-6.284496014016094e-05,-3.394514343673639e-05,-5.8125245610849973e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003115063595155369,-0.0,5.553299293139038e-07,7.441711449751362e-07,0.0,-8.300912381477665e-05,-8.553731759621599e-05,-4.1814066598589656e-05,-0.0,-0.0,2.0234777223150938e-06,-8.142025582791743e-05,-7.129749332452192e-05,-4.021340715327539e-05,-3.180315362136529e-05,1.964860540031114e-06,4.445955060091124e-05,-3.877917921322902e-05,-3.394514343673639e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0011643888904754934,-0.00014426356646120406,-9.610481791078421e-05,0.0,1.0743649829862926e-05,-5.139755198444347e-05,-0.00011570846247739684,-3.9208774186147564e-05,1.0112528287628848e-05,3.0499392293069625e-05,3.89556058434171e-05,-1.4935938118571974e-05,-5.9516946069939726e-05,-0.00011187187632913677,-9.937928168157009e-05,-6.757258785653077e-05,-5.691368023902602e-05,7.799370328841638e-08,-8.27997995113344e-05,-4.001765855548625e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00019968045299434046,-9.854528194292579e-05,-9.067879566899776e-05,-3.295847080574628e-05,-2.7168478207666602e-05,-9.659694587186775e-05,-0.00013321656265818108,1.9035264647731662e-07,2.0656673287296938e-05,2.4034390766692286e-05,5.0848611540947444e-05,1.1016212232150273e-05,2.1594040378739774e-05,-5.5580114840823496e-05,-0.00015508630557679165,-0.0001236632632817023,-0.00015020950238405558,-0.00011116516675139357,-8.802408072215426e-05,-7.553443325953682e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0002458631820038748,-0.00010029984235020665,-8.989186858906067e-05,-5.770623432643761e-05,-7.014304439686141e-05,-0.000129184800201071,-7.437813271347966e-05,7.188285024779734e-06,-2.3405278472273978e-05,8.366700159972183e-05,0.00011805317477016705,6.78623519785291e-05,8.633480526970711e-05,-7.376604807031038e-07,-0.00015143409701799714,-0.00016052664166849677,-0.00016031428263756816,-0.00016712444608586567,-0.0002702285028789598,-0.00010208014389252891,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00011381649808139316,-0.00012853900224732648,-7.8589873006084e-05,-4.961326895893606e-05,-7.368923124545217e-05,-8.904140787642661e-05,-8.176832354046695e-05,-4.641614552837021e-06,6.227181073130979e-05,9.372925449086639e-05,0.00014397438677981193,0.00012049540268348204,0.00011923985682587853,-5.272604839089619e-07,-0.0002050593195305955,-0.0001577251480966058,-9.956028412826099e-05,-0.00014288872963524567,-0.00022510278740142214,-0.0002979491549726707,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00015325073343250224,-0.00012604815072848495,-4.317256349973611e-06,-1.4477656396112157e-05,-8.554728785579447e-05,-0.00012679008560940376,-7.736057830884103e-05,-1.6514032330287876e-05,0.00010615875760051061,0.00016729758900305768,0.00019420966427041684,0.00018477147022107488,0.00014949777799656955,-0.00010194954765362683,-0.00023030613467332544,-0.00016305495834265698,-9.293149102117193e-05,-8.087309643293939e-05,-0.0001792015077337887,-0.0003235007839612429,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00021357274846074245,-6.93529887422101e-05,-4.0338414237131446e-05,-0.00010319138181598693,-0.00013255519479811256,-0.00015774942194115841,-0.0001320624974079787,-1.4714948506688997e-05,0.00016617832380765878,0.00017603927920376516,0.00021250733184486866,0.0002164137554855567,0.00019174541878850932,-0.00019028890977160814,-0.0001981140237184898,-0.0001692251300989073,-0.00010578794487033075,-7.460329842588545e-05,-0.00014474304562096652,-0.00031154045654731885,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.000446646624167584,-0.00020933591722690952,-0.0001000006638481098,-7.635465682249806e-05,-0.00012395312447696186,-0.00015404758276057193,-0.00017144872308500983,-0.0001803373579249997,6.040694158233249e-05,0.00016940726762435706,0.0001819098807504074,0.00023986865822743,0.00026176654027378326,0.0002220103840010039,-0.00022961196551806088,-0.00017177659316280024,-0.0001712364833521323,-0.0001344637503279974,-6.661951198606286e-05,-0.00013297432787403655,-0.00030819277984344844,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0003343106385704517,-0.0002341544389433134,-0.00010289409968140967,-8.365317853941966e-05,-0.00012876320116322123,-0.00016713861828324513,-0.0001856048893496276,-0.0002266501304483021,9.996194014947e-05,0.00016797705458354627,0.0002221386537218976,0.00023911820548994418,0.0003630317804106844,3.5587071796000414e-07,-0.0002217493228035484,-0.00016162124148134653,-0.00017262335165929723,-9.765145366137315e-05,-0.00010794021242248992,-0.00017008166933932579,-0.0002769208151028969,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00032059342868248457,-0.0001927464228936199,-0.00010548344141013064,-9.00685500113092e-05,-0.00014162758357978545,-0.00016699416132724728,-0.00020132940540833384,0.0,9.062509847652714e-05,0.00015443925047166116,0.00022945664231046234,0.00023558067616924388,0.00032462087645465806,4.489005804035622e-07,-0.00016227639709536347,-0.00015706823696227888,-0.00015485485955590183,-0.00016398027475394777,-0.0001492565051314684,-0.00011395588919865055,-0.00011232383931359649,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-8.922486401510347e-05,-0.00017471381878775288,-0.0001269513394860466,-9.320093204992384e-05,-0.00014549256802023214,-0.00016370360895537843,-0.00017332119647050226,-5.093027056578118e-07,7.551361434969898e-05,0.00015427069740960508,0.00022010133887953004,0.00022277084587702824,0.0002673914722777049,-2.2009904132255076e-05,-0.00010912058056384223,-0.0001157684833340294,-0.00019248702693819373,-0.00018299765092443565,-9.844832186325824e-05,-6.85392595090317e-05,-8.923190137342478e-05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00014398647487639667,-0.0001231295716300835,-0.00015127036919041948,-0.0001245472962548602,-0.0001519246272455005,-0.00011276708744913916,-7.742595706608117e-05,-1.0863782311958287e-06,9.452855674791676e-05,0.00019742096418078978,0.00019392492623082646,0.00019118645233514792,6.298261424113731e-05,-0.00012771903687532998,-0.00012883650965418857,-0.000127274204920682,-0.00011282472516802401,-6.417229621722391e-05,-6.378934496314488e-05,-8.059997981966418e-05,-0.00013517507036611847,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0001475474259972671,-9.192016024768096e-05,-0.00012986904186441833,-0.00015856282055163318,-0.00018616201323471746,-0.00010791390785661072,-1.4844402943742787e-05,9.562257307504931e-06,9.793339513047197e-05,0.00017832392976717748,0.0001456032490062522,7.354807281694771e-05,-5.7182620689487616e-05,-9.206184966647013e-05,-6.62443960359272e-05,-2.0249996445564985e-05,-3.4275078547386483e-05,-3.897591392047522e-05,-6.981400709195259e-05,-8.68710580252592e-05,-0.0002638800493838412,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.0001501842189676075,-9.155635645507776e-05,-6.876580989034073e-05,-6.998638630613601e-05,-0.00013474741540825793,-0.00013149764673220404,-6.405274837139365e-05,-4.589294834697903e-05,-7.115900395761931e-06,4.4177268762394014e-05,7.991417730925046e-05,-6.270768090017462e-06,-4.46524953370451e-05,-2.9715092020968732e-05,-0.0,-5.435628983365596e-05,-1.0719301747670347e-05,-2.181071052000426e-05,-8.322340266075759e-05,-0.00013004859376080795,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00011625049122169995,-5.329764090690544e-05,4.4413686507164085e-06,1.772090583579034e-06,-3.873592555499277e-05,-7.963109993815709e-05,-4.68681632126213e-05,-3.3805937856143216e-05,-6.84616000438354e-05,-1.3859576545356296e-05,-3.366490242169395e-07,-1.9965109360092335e-05,-4.351895755836495e-05,1.1909006180692763e-06,-3.738129808974915e-05,-5.3356126310495e-05,-1.8367844275685078e-05,-2.8900386182550254e-05,-0.00010902429331912511,-0.0007289428170489043,0.0,0.0,1.1815009038687585e-06,0.0,0.0,0.0,0.0,0.0,-0.00013687557837393705,-4.350604887948131e-05,0.00012699105728555755,8.005658121415816e-05,1.040014601253766e-05,-1.9921298152031182e-05,-4.83738020916256e-05,-3.243698977184077e-05,-4.4482531438842516e-05,-4.318492728674992e-05,-3.5474498574046116e-05,-3.3075530893585635e-05,-4.87000874535127e-05,-4.7810355902603536e-05,-2.449269808855253e-05,6.050017533961712e-07,5.617076854743123e-07,-0.0,-0.00010695947623675273,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00010224440794197708,8.06478127099287e-07,0.00010534180150368117,4.786125939993949e-05,4.161450832317052e-05,5.940875403936642e-07,-6.894347397445863e-05,-9.021191881030564e-05,-8.588272080759161e-05,-6.595014381683412e-05,-7.964235031047631e-05,-0.00010656859529076196,-4.0823463217236045e-05,5.288457946562814e-07,-0.0,0.00018527198217770175,0.0005891609660550845,-0.0008486285859184096,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.00022232785090115653,-3.496994818503248e-05,-2.7088787275580548e-05,3.0516365750812135e-05,8.3647056199798e-06,-5.186363349249729e-05,-0.000162753416173489,-0.00017843013591671835,-0.00013374558661216322,-0.00012220046604981697,-0.00016484832896583452,-8.874569657409978e-05,-0.00011159793689126122,-0.00025177253090768054]\n",
      "Intercept: 0.5232286178786091\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, \n",
    "                 regParam=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for linear SVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"Intercept: \" + str(lsvcModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7822b1ec",
   "metadata": {},
   "source": [
    "### One-vs-Rest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85669482",
   "metadata": {},
   "source": [
    "Los algoritmos como Perceptron, Regresión logística y LSVC se diseñaron para la clasificación binaria y no admiten de forma nativa tareas de clasificación con más de dos clases.\n",
    "\n",
    "Un enfoque para usar algoritmos de clasificación binaria para problemas de clasificación múltiple es dividir el conjunto de datos de clasificación de clases múltiples en múltiples conjuntos de datos de clasificación binaria y ajustar un modelo de clasificación binaria en cada uno. \n",
    "\n",
    "Un ejemplo de este enfoque es la estrategia One-vs-Rest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0cb9cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0714286\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# load data file.\n",
    "inputData = spark.read.format(\"libsvm\") \\\n",
    "    .load(\"data/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "# generate the train/test split.\n",
    "(train, test) = inputData.randomSplit([0.8, 0.2])\n",
    "\n",
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(train)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(test)\n",
    "\n",
    "# obtain evaluator.\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "\n",
    "# compute the classification error on test data.\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d8645",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cabe99",
   "metadata": {},
   "source": [
    "Es uno de los algoritmos más simples y poderosos para la clasificación basado en el **Teorema de Bayes** con una suposición de independencia entre los predictores. Naive Bayes es fácil de construir y particularmente **útil para conjuntos de datos muy grandes**.\n",
    "\n",
    "Ventajas:\n",
    "- Es fácil y rápido predecir la clase de conjunto de datos de prueba. También funciona bien en la predicción multiclase.\n",
    "- Cuando se mantiene la suposición de independencia, un clasificador Naive - Bayes funciona mejor en comparación con otros modelos como la Regresión Logística y **se necesitan menos datos de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b42763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|label|            features|       rawPrediction|probability|prediction|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[-172664.79564650...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[98,99,100,1...|[-176279.15054306...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[-189600.55409526...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-274673.88337431...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-183393.03869049...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[-256992.48807619...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[-210411.53649773...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-170627.63616681...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-212157.96750469...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-183253.80108550...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[-246528.93739632...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[-158348.34683571...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-210229.50765957...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-242985.16248889...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-94622.933454005...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-266465.39689814...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-144989.71469229...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-283834.57437738...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|[-155256.59399829...|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[100,101,102...|[-147726.11958982...|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load training data\n",
    "data = spark.read.format(\"libsvm\") \\\n",
    "    .load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, \n",
    "                modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d4f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
